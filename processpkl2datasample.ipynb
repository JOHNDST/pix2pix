{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coastline loaded\n",
      "d2m loaded\n",
      "land_use loaded\n",
      "ndvi loaded\n",
      "phfs loaded\n",
      "pm25 loaded\n",
      "t2m loaded\n",
      "tp loaded\n",
      "u10 loaded\n",
      "v10 loaded\n"
     ]
    }
   ],
   "source": [
    "# load pickle files in the folder\n",
    "os.chdir(\"E:/Coding/pix2pix_pytorch/\")\n",
    "# Load all the pkl files in the folder, all the processed data are dictionaries with keys 'sample_id' and values of np.array\n",
    "pkl_path = 'pm25/'\n",
    "pkl_files = [pkl_path + f for f in os.listdir(pkl_path) if f.endswith('.pkl')]\n",
    "var_list = []\n",
    "for pkl_file in pkl_files:\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        exec(f'{str(pkl_file).split(\"/\")[-1].split(\".\")[0]} = pickle.load(f)')\n",
    "        var_list.append(str(pkl_file).split(\"/\")[-1].split(\".\")[0])\n",
    "        print(f'{str(pkl_file).split(\"/\")[-1].split(\".\")[0]} loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_shape(data):\n",
    "    \"\"\"\n",
    "    Ensure that the input data is of shape (256, 256).\n",
    "    \n",
    "    Parameters:\n",
    "    - data: numpy array of shape (256, 256) or (1, 256, 256)\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array of shape (256, 256)\n",
    "    \"\"\"\n",
    "    if data.ndim == 3 and data.shape[0] == 1:\n",
    "        return data.squeeze(0)  # Remove the first dimension if it is 1\n",
    "    elif data.ndim == 2:\n",
    "        return data  # Already in the correct shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing coastline\n",
      "coastline processed\n",
      "Processing d2m\n",
      "d2m processed\n",
      "Processing land_use\n",
      "land_use processed\n",
      "Processing ndvi\n",
      "ndvi processed\n",
      "Processing phfs\n",
      "phfs processed\n",
      "Processing pm25\n",
      "pm25 processed\n",
      "Processing t2m\n",
      "t2m processed\n",
      "Processing tp\n",
      "tp processed\n",
      "Processing u10\n",
      "u10 processed\n",
      "Processing v10\n",
      "v10 processed\n"
     ]
    }
   ],
   "source": [
    "for var in var_list:\n",
    "    print(f'Processing {var}')\n",
    "    for sample in eval(f'{var}'+'.keys()'):\n",
    "        eval(f'{var}')[sample] = unify_shape(eval(f'{var}')[sample])\n",
    "    # find max and min among all samples\n",
    "    max_val = np.max([np.max(eval(f'{var}')[sample]) for sample in eval(f'{var}')])\n",
    "    min_val = np.min([np.min(eval(f'{var}')[sample]) for sample in eval(f'{var}')])\n",
    "    # normalize all samples\n",
    "    for sample in eval(f'{var}'):\n",
    "        eval(f'{var}')[sample] = (eval(f'{var}')[sample] - min_val) / (max_val - min_val)\n",
    "    print(f'{var} processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([np.max(eval(f'{var}')[sample]) for sample in eval(f'{var}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_order = [ 'land_use','ndvi', 'coastline','phfs','d2m',\n",
    "                't2m', 'tp','u10', 'v10', 'pm25']\n",
    "sample_id = list(pm25.keys())\n",
    "\n",
    "# stack data based on sample_id and save to a file\n",
    "data = dict()\n",
    "\n",
    "for sample in sample_id:\n",
    "    data_sp = []\n",
    "    for layer in layer_order:\n",
    "        data_sp.append(eval(layer)[sample])\n",
    "\n",
    "    data[sample] = np.stack(data_sp, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 saved\n",
      "87 saved\n",
      "88 saved\n",
      "102 saved\n",
      "103 saved\n",
      "119 saved\n",
      "120 saved\n",
      "121 saved\n",
      "134 saved\n",
      "135 saved\n",
      "152 saved\n",
      "153 saved\n",
      "154 saved\n",
      "160 saved\n",
      "161 saved\n",
      "162 saved\n",
      "163 saved\n",
      "175 saved\n",
      "176 saved\n",
      "185 saved\n",
      "186 saved\n",
      "187 saved\n",
      "188 saved\n",
      "189 saved\n",
      "190 saved\n",
      "191 saved\n",
      "192 saved\n",
      "193 saved\n",
      "194 saved\n",
      "195 saved\n",
      "196 saved\n",
      "197 saved\n",
      "207 saved\n",
      "208 saved\n",
      "218 saved\n",
      "219 saved\n",
      "220 saved\n",
      "221 saved\n",
      "222 saved\n",
      "223 saved\n",
      "224 saved\n",
      "225 saved\n",
      "226 saved\n",
      "227 saved\n",
      "228 saved\n",
      "229 saved\n",
      "246 saved\n",
      "248 saved\n",
      "249 saved\n",
      "250 saved\n",
      "251 saved\n",
      "252 saved\n",
      "253 saved\n",
      "254 saved\n",
      "255 saved\n",
      "256 saved\n",
      "257 saved\n",
      "258 saved\n",
      "259 saved\n",
      "260 saved\n",
      "261 saved\n",
      "262 saved\n",
      "278 saved\n",
      "279 saved\n",
      "280 saved\n",
      "281 saved\n",
      "282 saved\n",
      "283 saved\n",
      "284 saved\n",
      "285 saved\n",
      "286 saved\n",
      "287 saved\n",
      "288 saved\n",
      "289 saved\n",
      "290 saved\n",
      "291 saved\n",
      "292 saved\n",
      "293 saved\n",
      "294 saved\n",
      "295 saved\n",
      "312 saved\n",
      "313 saved\n",
      "314 saved\n",
      "315 saved\n",
      "316 saved\n",
      "317 saved\n",
      "318 saved\n",
      "319 saved\n",
      "320 saved\n",
      "321 saved\n",
      "322 saved\n",
      "323 saved\n",
      "324 saved\n",
      "325 saved\n",
      "326 saved\n",
      "327 saved\n",
      "328 saved\n",
      "345 saved\n",
      "346 saved\n",
      "347 saved\n",
      "348 saved\n",
      "349 saved\n",
      "350 saved\n",
      "351 saved\n",
      "352 saved\n",
      "353 saved\n",
      "354 saved\n",
      "355 saved\n",
      "356 saved\n",
      "357 saved\n",
      "358 saved\n",
      "359 saved\n",
      "360 saved\n",
      "376 saved\n",
      "377 saved\n",
      "378 saved\n",
      "379 saved\n",
      "380 saved\n",
      "381 saved\n",
      "382 saved\n",
      "383 saved\n",
      "384 saved\n",
      "385 saved\n",
      "386 saved\n",
      "387 saved\n",
      "388 saved\n",
      "389 saved\n",
      "390 saved\n",
      "391 saved\n",
      "392 saved\n",
      "393 saved\n",
      "408 saved\n",
      "409 saved\n",
      "410 saved\n",
      "411 saved\n",
      "412 saved\n",
      "413 saved\n",
      "414 saved\n",
      "415 saved\n",
      "416 saved\n",
      "417 saved\n",
      "418 saved\n",
      "419 saved\n",
      "420 saved\n",
      "421 saved\n",
      "422 saved\n",
      "423 saved\n",
      "424 saved\n",
      "425 saved\n",
      "426 saved\n",
      "440 saved\n",
      "441 saved\n",
      "442 saved\n",
      "443 saved\n",
      "444 saved\n",
      "445 saved\n",
      "446 saved\n",
      "447 saved\n",
      "448 saved\n",
      "449 saved\n",
      "450 saved\n",
      "451 saved\n",
      "452 saved\n",
      "453 saved\n",
      "454 saved\n",
      "455 saved\n",
      "456 saved\n",
      "457 saved\n",
      "458 saved\n",
      "459 saved\n",
      "471 saved\n",
      "472 saved\n",
      "473 saved\n",
      "474 saved\n",
      "475 saved\n",
      "476 saved\n",
      "477 saved\n",
      "478 saved\n",
      "479 saved\n",
      "480 saved\n",
      "481 saved\n",
      "482 saved\n",
      "483 saved\n",
      "484 saved\n",
      "485 saved\n",
      "486 saved\n",
      "487 saved\n",
      "488 saved\n",
      "489 saved\n",
      "490 saved\n",
      "491 saved\n",
      "503 saved\n",
      "504 saved\n",
      "505 saved\n",
      "506 saved\n",
      "507 saved\n",
      "508 saved\n",
      "509 saved\n",
      "510 saved\n",
      "511 saved\n",
      "512 saved\n",
      "513 saved\n",
      "514 saved\n",
      "515 saved\n",
      "516 saved\n",
      "517 saved\n",
      "518 saved\n",
      "519 saved\n",
      "520 saved\n",
      "521 saved\n",
      "522 saved\n",
      "523 saved\n",
      "524 saved\n",
      "536 saved\n",
      "537 saved\n",
      "538 saved\n",
      "539 saved\n",
      "540 saved\n",
      "541 saved\n",
      "542 saved\n",
      "543 saved\n",
      "544 saved\n",
      "545 saved\n",
      "546 saved\n",
      "547 saved\n",
      "548 saved\n",
      "549 saved\n",
      "550 saved\n",
      "551 saved\n",
      "552 saved\n",
      "553 saved\n",
      "554 saved\n",
      "555 saved\n",
      "556 saved\n",
      "557 saved\n",
      "570 saved\n",
      "571 saved\n",
      "572 saved\n",
      "573 saved\n",
      "574 saved\n",
      "579 saved\n",
      "580 saved\n",
      "581 saved\n",
      "582 saved\n",
      "583 saved\n",
      "584 saved\n",
      "585 saved\n",
      "586 saved\n",
      "587 saved\n",
      "588 saved\n",
      "589 saved\n",
      "590 saved\n",
      "604 saved\n",
      "605 saved\n",
      "606 saved\n",
      "614 saved\n",
      "615 saved\n",
      "616 saved\n",
      "617 saved\n",
      "618 saved\n",
      "619 saved\n",
      "620 saved\n",
      "621 saved\n",
      "622 saved\n",
      "651 saved\n",
      "652 saved\n",
      "653 saved\n",
      "654 saved\n",
      "655 saved\n"
     ]
    }
   ],
   "source": [
    "# save each sample as a npy file in the folder\n",
    "for sample in sample_id:\n",
    "    np.save(f'E:/Coding/pix2pix_pytorch/pm25/all/{sample}.npy', data[sample])\n",
    "    print(f'{sample} saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
